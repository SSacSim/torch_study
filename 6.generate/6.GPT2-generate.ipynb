{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "torch.manual_seed(799)\n",
    "tkz = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "mdl = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "ln = 10 # 길이\n",
    "cue = \"It will\"\n",
    "gen = tkz.encode(cue) # cue 토큰화\n",
    "ctx = torch.tensor([gen]) # totensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will is not a matter of whether the government will be\n"
     ]
    }
   ],
   "source": [
    "prv=None\n",
    "for i in range(ln):\n",
    "    op= mdl(ctx, past_key_values=prv)\n",
    "    prv = op.past_key_values\n",
    "    tkn = torch.argmax(op['logits'].squeeze(0))\n",
    "\n",
    "    gen += [tkn.tolist()]\n",
    "    ctx = tkn.unsqueeze(0)\n",
    "\n",
    "seq = tkz.decode(gen)\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will be interesting to see how the new system\n"
     ]
    }
   ],
   "source": [
    "# greedy한 결과값만 취하므로 늘 똑같은 output를 생성 \n",
    "ip_ids = tkz.encode(cue, return_tensors='pt')\n",
    "op_greedy = mdl.generate(ip_ids, max_length=ln, pad_token_id=tkz.eos_token_id)\n",
    "seq = tkz.decode(op_greedy[0], skip_special_tokens=True)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will be interesting to see how this plays out\n",
      "It will be interesting to see how long it takes\n",
      "It will be interesting to see what happens with the\n"
     ]
    }
   ],
   "source": [
    "# beam search\n",
    "# num_beams : 단어 예측값을 지속적으로 곱하여 가장 높은 확률이 되는 상위 n개를 유지하며 생성\n",
    "op_beam = mdl.generate(\n",
    "    ip_ids, \n",
    "    max_length=ln, \n",
    "    num_beams=10, \n",
    "    num_return_sequences=3, \n",
    "    pad_token_id=tkz.eos_token_id\n",
    ")\n",
    "\n",
    "for op_beam_cur in op_beam:\n",
    "    print(tkz.decode(op_beam_cur, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will not be a long-term solution.\n",
      "It will take a lot of time and a lot\n",
      "It will also be a great way to learn about\n"
     ]
    }
   ],
   "source": [
    "# top-k sampling\n",
    "# top-k개의 확률값을 정규화하여 랜덤하게 뽑아 선택하는 방식 \n",
    "# 일정하지 않고, 다양한 결과를 얻을 수 있음\n",
    "# top_k= 0 으로 설정시, 모든 단어로 샘플링 진행\n",
    "for i in range(3):\n",
    "    #torch.manual_seed(i)\n",
    "    op = mdl.generate(\n",
    "        ip_ids, \n",
    "        do_sample=True, \n",
    "        max_length=ln, \n",
    "        top_k=4,\n",
    "        pad_token_id=tkz.eos_token_id\n",
    "    )\n",
    "\n",
    "    seq = tkz.decode(op[0], skip_special_tokens=True)\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will be interesting to see if he is able\n",
      "It will also provide a better understanding of how the\n",
      "It will be interesting to see how the next few\n"
     ]
    }
   ],
   "source": [
    "# top-p sampling 방식\n",
    "# 누적확률임계값을 지정하여 단어의 폭을 조정\n",
    "# top_k 값을 변경하여 동시에 사용가능\n",
    "for i in range(3):\n",
    "    #torch.manual_seed(i)\n",
    "    op = mdl.generate(\n",
    "        ip_ids, \n",
    "        do_sample=True, \n",
    "        max_length=ln, \n",
    "        top_p=0.75, \n",
    "        top_k = 0,\n",
    "        pad_token_id=tkz.eos_token_id\n",
    "    )\n",
    "\n",
    "    seq = tkz.decode(op[0], skip_special_tokens=True)\n",
    "    print(seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa996f07c7a4790828b1e22eaa2430332fe2e2f9495926bea94e65a6711ba0db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
